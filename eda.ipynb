{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "from __future__ import unicode_literals, print_function, division\n",
    "from io import open\n",
    "import unicodedata\n",
    "import re\n",
    "from pickle import dump\n",
    "from unicodedata import normalize\n",
    "import random\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import string\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import numpy as np\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-19T10:14:45.198625137Z",
     "start_time": "2023-10-19T10:14:43.721816004Z"
    }
   },
   "id": "c77fd275fc6acea5"
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-10-18T13:26:40.508967546Z",
     "start_time": "2023-10-18T13:26:40.461670817Z"
    }
   },
   "outputs": [],
   "source": [
    "# load doc into memory\n",
    "def load_doc(filename, col):\n",
    "\t# open the file\n",
    "\tdf = pd.read_csv(filename, sep='\\t', header=None)\n",
    "\ttext = \"\"\n",
    "\tfor i in range(df[col].size):\n",
    "\t\tline = str(df[col][i])\n",
    "\t\ttext += line+\"\\n\"\n",
    "\treturn text\n",
    "\n",
    "# split a loaded document into sentences\n",
    "def to_sentences(doc):\n",
    "\treturn doc.strip().split('\\n')\n",
    "\n",
    "# clean a list of lines\n",
    "def clean_lines(lines):\n",
    "\tcleaned = list()\n",
    "\t# prepare regex for char filtering\n",
    "\tre_print = re.compile('[^%s]' % re.escape(string.printable))\n",
    "\t# prepare translation table for removing punctuation\n",
    "\ttable = str.maketrans('', '', string.punctuation)\n",
    "\tfor line in lines:\n",
    "\t\t# normalize unicode characters\n",
    "\t\tline = normalize('NFD', line).encode('ascii', 'ignore')\n",
    "\t\tline = line.decode('UTF-8')\n",
    "\t\t# tokenize on white space\n",
    "\t\tline = line.split()\n",
    "\t\t# convert to lower case\n",
    "\t\tline = [word.lower() for word in line]\n",
    "\t\t# remove punctuation from each token\n",
    "\t\tline = [word.translate(table) for word in line]\n",
    "\t\t# remove non-printable chars form each token\n",
    "\t\tline = [re_print.sub('', w) for w in line]\n",
    "\t\t# remove tokens with numbers in them\n",
    "\t\tline = [word for word in line if word.isalpha()]\n",
    "\t\t# store as string\n",
    "\t\tcleaned.append(' '.join(line))\n",
    "\treturn cleaned\n",
    "\n",
    "# save a list of clean sentences to file\n",
    "def save_clean_sentences(sentences, filename):\n",
    "\tdump(sentences, open(filename, 'wb'))\n",
    "\tprint('Saved: %s' % filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: data/english.pkl\n",
      "statement by the president\n",
      "you all deserved your holiday\n",
      "you all look wellrested and i hope that you are now looking forward very much to getting back to our work on european matters\n",
      "i am afraid that i have to start with some sad news\n",
      "since we last met here we have learned with deep sadness of the deaths of two great europeans gaston thorn and raymond barre both eminent men who dedicated themselves to the service of their countries as outstanding prime ministers and members of the european commission\n",
      "gaston thorn was a member of the european parliament for ten years from to\n",
      "from to he was luxembourgs minister for foreign affairs and then became that countrys prime minister in holding office until\n",
      "he served as president of the european commission from until\n",
      "under his guidance the european community negotiated the terms for the accession of spain and portugal initiated the common fisheries policy and reached a solution to the contentious issues surrounding the communitys budgetary resources and its future financing\n",
      "raymond barre was the vicepresident of the european commission from to and prime minister of france from to\n",
      "Saved: data/french.pkl\n",
      "prohlaseni predsednictvi\n",
      "vsichni jste si svou dovolenou zaslouzili\n",
      "vypadate odpocate a doufam ze se tesite na navrat k praci kterou je treba vykonat v oblasti evropskych zalezitosti\n",
      "bohuzel vsak budu muset zacit smutnou zpravou\n",
      "po nasem poslednim setkani jsme se s hlubokym zarmutkem rozloucili se dvema velkymi evropany gastonem thornem a raymondem barreem vyznamnymi muzi kteri obetovali sve zivoty sluzbe vlasti jako vynikajici premier i jako komisar evropske komise\n",
      "gaston thorn byl deset let od roku do roku poslancem evropskeho parlamentu\n",
      "v letech az byl ministrem zahranicnich veci lucemburska a v letech az jeho premierem\n",
      "od roku az do roku vykonaval funkci predsedy evropske komise\n",
      "pod jeho vedenim projednalo evropske spolecenstvi podminky pristoupeni spanelska a portugalska iniciovalo spolecnou politiku rybolovu a dospelo k vyreseni spornych otazek v oblasti rozpoctovych zdroju a pristiho financovani spolecenstvi\n",
      "raymond barre byl v letech az mistopredsedou evropske komise a v letech az premierem francie\n"
     ]
    }
   ],
   "source": [
    "# load English data\n",
    "filename = 'downloads/europarl-v9.cs-en.tsv'\n",
    "doc = load_doc(filename, 1)\n",
    "sentences = to_sentences(doc)\n",
    "sentences = clean_lines(sentences)\n",
    "save_clean_sentences(sentences, 'data/english.pkl')\n",
    "# spot check\n",
    "for i in range(10):\n",
    "\tprint(sentences[i])\n",
    "\n",
    "# load CS data\n",
    "doc = load_doc(filename, 0)\n",
    "sentences = to_sentences(doc)\n",
    "sentences = clean_lines(sentences)\n",
    "save_clean_sentences(sentences, 'data/french.pkl')\n",
    "# spot check\n",
    "for i in range(10):\n",
    "\tprint(sentences[i])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-18T13:27:11.054007180Z",
     "start_time": "2023-10-18T13:26:43.942193324Z"
    }
   },
   "id": "c485154e57aa2535"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "data": {
      "text/plain": "                                                  English  \\\n0                              statement by the president   \n1                           you all deserved your holiday   \n2       you all look wellrested and i hope that you ar...   \n3       i am afraid that i have to start with some sad...   \n4       since we last met here we have learned with de...   \n...                                                   ...   \n651580    approval of the minutes of the previous sitting   \n651581                                                nan   \n651582                agenda for next sitting see minutes   \n651583                                                nan   \n651584                             closure of the sitting   \n\n                                                   French  \n0                                prohlaseni predsednictvi  \n1               vsichni jste si svou dovolenou zaslouzili  \n2       vypadate odpocate a doufam ze se tesite na nav...  \n3           bohuzel vsak budu muset zacit smutnou zpravou  \n4       po nasem poslednim setkani jsme se s hlubokym ...  \n...                                                   ...  \n651580  dopady tezby bridlicoveho plynu a bridlicne ro...  \n651581                                                nan  \n651582  opravy hlasovani a sdeleni o umyslu hlasovat v...  \n651583                                                nan  \n651584            schvaleni zapisu z predchoziho zasedani  \n\n[651585 rows x 2 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>English</th>\n      <th>French</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>statement by the president</td>\n      <td>prohlaseni predsednictvi</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>you all deserved your holiday</td>\n      <td>vsichni jste si svou dovolenou zaslouzili</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>you all look wellrested and i hope that you ar...</td>\n      <td>vypadate odpocate a doufam ze se tesite na nav...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>i am afraid that i have to start with some sad...</td>\n      <td>bohuzel vsak budu muset zacit smutnou zpravou</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>since we last met here we have learned with de...</td>\n      <td>po nasem poslednim setkani jsme se s hlubokym ...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>651580</th>\n      <td>approval of the minutes of the previous sitting</td>\n      <td>dopady tezby bridlicoveho plynu a bridlicne ro...</td>\n    </tr>\n    <tr>\n      <th>651581</th>\n      <td>nan</td>\n      <td>nan</td>\n    </tr>\n    <tr>\n      <th>651582</th>\n      <td>agenda for next sitting see minutes</td>\n      <td>opravy hlasovani a sdeleni o umyslu hlasovat v...</td>\n    </tr>\n    <tr>\n      <th>651583</th>\n      <td>nan</td>\n      <td>nan</td>\n    </tr>\n    <tr>\n      <th>651584</th>\n      <td>closure of the sitting</td>\n      <td>schvaleni zapisu z predchoziho zasedani</td>\n    </tr>\n  </tbody>\n</table>\n<p>651585 rows Ã— 2 columns</p>\n</div>"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('data/french.pkl', 'rb') as f:\n",
    "    fr_voc = pickle.load(f)\n",
    "\n",
    "with open('data/english.pkl', 'rb') as f:\n",
    "    eng_voc = pickle.load(f)\n",
    "    \n",
    "data = pd.DataFrame(zip(eng_voc, fr_voc), columns = ['English', 'French'])\n",
    "data"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-19T10:14:54.399464829Z",
     "start_time": "2023-10-19T10:14:53.773616531Z"
    }
   },
   "id": "41de5d1da3edc5b5"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "data.to_csv('eng-fra.txt', header=False, index=False, sep='\\t')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-19T10:15:36.424242121Z",
     "start_time": "2023-10-19T10:15:34.019758572Z"
    }
   },
   "id": "fd62151e7ad78a54"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "SOS_token = 0\n",
    "EOS_token = 1\n",
    "\n",
    "\n",
    "class Lang:\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        self.word2index = {}\n",
    "        self.word2count = {}\n",
    "        self.index2word = {0: \"SOS\", 1: \"EOS\"}\n",
    "        self.n_words = 2  # Count SOS and EOS\n",
    "\n",
    "    def addSentence(self, sentence):\n",
    "        for word in sentence.split(' '):\n",
    "            self.addWord(word)\n",
    "\n",
    "    def addWord(self, word):\n",
    "        if word not in self.word2index:\n",
    "            self.word2index[word] = self.n_words\n",
    "            self.word2count[word] = 1\n",
    "            self.index2word[self.n_words] = word\n",
    "            self.n_words += 1\n",
    "        else:\n",
    "            self.word2count[word] += 1"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-19T10:15:36.472616441Z",
     "start_time": "2023-10-19T10:15:36.426152267Z"
    }
   },
   "id": "c2bb6ea34a921620"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "# Turn a Unicode string to plain ASCII, thanks to\n",
    "# https://stackoverflow.com/a/518232/2809427\n",
    "def unicodeToAscii(s):\n",
    "    return ''.join(\n",
    "        c for c in unicodedata.normalize('NFD', s)\n",
    "        if unicodedata.category(c) != 'Mn'\n",
    "    )\n",
    "\n",
    "# Lowercase, trim, and remove non-letter characters\n",
    "def normalizeString(s):\n",
    "    s = unicodeToAscii(s.lower().strip())\n",
    "    s = re.sub(r\"([.!?])\", r\" \\1\", s)\n",
    "    s = re.sub(r\"[^a-zA-Z!?]+\", r\" \", s)\n",
    "    return s.strip()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-19T10:15:36.472909931Z",
     "start_time": "2023-10-19T10:15:36.468469514Z"
    }
   },
   "id": "7cb179fa82c2f7ac"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "def readLangs(lang1, lang2, reverse=False):\n",
    "    print(\"Reading lines...\")\n",
    "\n",
    "    # Read the file and split into lines\n",
    "    lines = open('%s-%s.txt' % (lang1, lang2), encoding='utf-8').\\\n",
    "        read().strip().split('\\n')\n",
    "    # Split every line into pairs and normalize\n",
    "    pairs = [[normalizeString(s) for s in l.split('\\t')] for l in lines]\n",
    "\n",
    "\n",
    "    # Reverse pairs, make Lang instances\n",
    "    if reverse:\n",
    "        pairs = [list(reversed(p)) for p in pairs]\n",
    "        input_lang = Lang(lang2)\n",
    "        output_lang = Lang(lang1)\n",
    "    else:\n",
    "        input_lang = Lang(lang1)\n",
    "        output_lang = Lang(lang2)\n",
    "\n",
    "    return input_lang, output_lang, pairs"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-19T10:15:36.473102609Z",
     "start_time": "2023-10-19T10:15:36.468666039Z"
    }
   },
   "id": "8ef1c3fedf332283"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "('he is',\n 'i hope',\n 'you should',\n 'i just',\n 'i didn t',\n 'they re ',\n 'i d like',\n 'we have',\n 'they are',\n 'you re very',\n 'i was',\n 'i know',\n 'would you',\n 'she is',\n 'i really',\n 'i thought',\n 'we are',\n 'i think',\n 'i feel',\n 'i am ',\n 'tom is',\n 'no one',\n 'i will',\n 'this is',\n 'i love',\n 'i want',\n 'i like',\n 'i can',\n 'i m ',\n 'you re not',\n 'i am',\n 'she s ',\n 'if you',\n 'it was',\n 'i had',\n 'have you',\n 'why don t',\n 'i can t',\n 'do you',\n 'i need',\n 'did you',\n 'we re ',\n 'can you',\n 'you can t',\n 'you have',\n 'she was',\n 'you don t',\n 'are you',\n 'he has',\n 'he was',\n 'what do',\n 'you re ',\n 'you must',\n 'i m not',\n 'he s ',\n 'i don t',\n 'it is',\n 'i have',\n 'you are')"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MAX_LENGTH = 12\n",
    "\n",
    "eng_prefixes = [\n",
    "    \"i am \", \"i m \",\n",
    "    \"he is\", \"he s \",\n",
    "    \"she is\", \"she s \",\n",
    "    \"you are\", \"you re \",\n",
    "    \"we are\", \"we re \",\n",
    "    \"they are\", \"they re \", \"I don t\", \"Do you\", \"I want\", \"Are you\", \"I have\", \"I think\",\n",
    "       \"I can t\", \"I was\", \"He is\", \"I m not\", \"This is\", \"I just\", \"I didn t\",\n",
    "       \"I am\", \"I thought\", \"I know\", \"Tom is\", \"I had\", \"Did you\", \"Have you\",\n",
    "       \"Can you\", \"He was\", \"You don t\", \"I d like\", \"It was\", \"You should\",\n",
    "       \"Would you\", \"I like\", \"It is\", \"She is\", \"You can t\", \"He has\",\n",
    "       \"What do\", \"If you\", \"I need\", \"No one\", \"You are\", \"You have\",\n",
    "       \"I feel\", \"I really\", \"Why don t\", \"I hope\", \"I will\", \"We have\",\n",
    "       \"You re not\", \"You re very\", \"She was\", \"I love\", \"You must\", \"I can\"]\n",
    "eng_prefixes = (map(lambda x: x.lower(), eng_prefixes))\n",
    "eng_prefixes = tuple(set(eng_prefixes))\n",
    "\n",
    "def filterPair(p):\n",
    "    return len(p[0].split(' ')) < MAX_LENGTH and \\\n",
    "        len(p[1].split(' ')) < MAX_LENGTH and \\\n",
    "        p[1].startswith(eng_prefixes)\n",
    "\n",
    "\n",
    "def filterPairs(pairs):\n",
    "    return [pair for pair in pairs if filterPair(pair)]\n",
    "eng_prefixes"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-19T10:15:36.473593035Z",
     "start_time": "2023-10-19T10:15:36.468809182Z"
    }
   },
   "id": "a56fe3354b2e8550"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading lines...\n",
      "Read 651585 sentence pairs\n",
      "Trimmed to 3962 sentence pairs\n",
      "Counting words...\n",
      "Counted words:\n",
      "fra 7476\n",
      "eng 3832\n",
      "['proto vitam toto usneseni', 'we have always intended to include wine']\n"
     ]
    }
   ],
   "source": [
    "def prepareData(lang1, lang2,reverse = False):\n",
    "    input_lang, output_lang, pairs = readLangs(lang1, lang2, reverse)\n",
    "    print(\"Read %s sentence pairs\" % len(pairs))\n",
    "    pairs = filterPairs(pairs)\n",
    "    print(\"Trimmed to %s sentence pairs\" % len(pairs))\n",
    "    print(\"Counting words...\")\n",
    "    for pair in pairs:\n",
    "        input_lang.addSentence(pair[0])\n",
    "        output_lang.addSentence(pair[1])\n",
    "    print(\"Counted words:\")\n",
    "    print(input_lang.name, input_lang.n_words)\n",
    "    print(output_lang.name, output_lang.n_words)\n",
    "    return input_lang, output_lang, pairs\n",
    "\n",
    "\n",
    "input_lang, output_lang, pairs = prepareData('eng', 'fra', True)\n",
    "print(random.choice(pairs))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-19T10:15:57.181207950Z",
     "start_time": "2023-10-19T10:15:36.468982974Z"
    }
   },
   "id": "eca0c00c081974c7"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# The Translator\n",
    "## The Encoder"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a6073e773d55567d"
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "class EncoderRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super(EncoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        embedded = self.embedding(input).view(1, 1, -1)\n",
    "        output = embedded\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, 1, self.hidden_size, device=device)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-19T10:15:57.182859301Z",
     "start_time": "2023-10-19T10:15:57.181782967Z"
    }
   },
   "id": "edce4e892e32ff40"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## The Attention Decoder"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d326ee12d1198f70"
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "class AttnDecoderRNN(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size, dropout_p=0.1, max_length=MAX_LENGTH):\n",
    "        super(AttnDecoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.dropout_p = dropout_p\n",
    "        self.max_length = max_length\n",
    "\n",
    "        self.embedding = nn.Embedding(self.output_size, self.hidden_size)\n",
    "        self.attn = nn.Linear(self.hidden_size * 2, self.max_length)\n",
    "        self.attn_combine = nn.Linear(self.hidden_size * 2, self.hidden_size)\n",
    "        self.dropout = nn.Dropout(self.dropout_p)\n",
    "        self.gru = nn.GRU(self.hidden_size, self.hidden_size)\n",
    "        self.out = nn.Linear(self.hidden_size, self.output_size)\n",
    "\n",
    "    def forward(self, input, hidden, encoder_outputs):\n",
    "        embedded = self.embedding(input).view(1, 1, -1)\n",
    "        embedded = self.dropout(embedded)\n",
    "\n",
    "        attn_weights = F.softmax(\n",
    "            self.attn(torch.cat((embedded[0], hidden[0]), 1)), dim=1)\n",
    "        attn_applied = torch.bmm(attn_weights.unsqueeze(0),\n",
    "                                 encoder_outputs.unsqueeze(0))\n",
    "\n",
    "        output = torch.cat((embedded[0], attn_applied[0]), 1)\n",
    "        output = self.attn_combine(output).unsqueeze(0)\n",
    "\n",
    "        output = F.relu(output)\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "\n",
    "        output = F.log_softmax(self.out(output[0]), dim=1)\n",
    "        return output, hidden, attn_weights\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, 1, self.hidden_size, device=device)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-19T10:15:57.228702809Z",
     "start_time": "2023-10-19T10:15:57.185670946Z"
    }
   },
   "id": "ef8248452237efe"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Training"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e56381b188c3151c"
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "import time\n",
    "import math\n",
    "\n",
    "def asMinutes(s):\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)\n",
    "\n",
    "def timeSince(since, percent):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    es = s / (percent)\n",
    "    rs = es - s\n",
    "    return '%s (- %s)' % (asMinutes(s), asMinutes(rs))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-19T10:15:57.229058488Z",
     "start_time": "2023-10-19T10:15:57.228538245Z"
    }
   },
   "id": "928d274d57b4070"
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "def indexesFromSentence(lang, sentence):\n",
    "    return [lang.word2index[word] for word in sentence.split(' ')]\n",
    "\n",
    "def tensorFromSentence(lang, sentence):\n",
    "    indexes = indexesFromSentence(lang, sentence)\n",
    "    indexes.append(EOS_token)\n",
    "    return torch.tensor(indexes, dtype=torch.long, device=device).view(1, -1)\n",
    "\n",
    "def tensorsFromPair(pair):\n",
    "    input_tensor = tensorFromSentence(input_lang, pair[0])\n",
    "    target_tensor = tensorFromSentence(output_lang, pair[1])\n",
    "    return (input_tensor, target_tensor)\n",
    "\n",
    "def get_dataloader(batch_size):\n",
    "    input_lang, output_lang, pairs = prepareData('eng', 'fra', True)\n",
    "\n",
    "    n = len(pairs)\n",
    "    input_ids = np.zeros((n, MAX_LENGTH), dtype=np.int32)\n",
    "    target_ids = np.zeros((n, MAX_LENGTH), dtype=np.int32)\n",
    "\n",
    "    for idx, (inp, tgt) in enumerate(pairs):\n",
    "        inp_ids = indexesFromSentence(input_lang, inp)\n",
    "        tgt_ids = indexesFromSentence(output_lang, tgt)\n",
    "        inp_ids.append(EOS_token)\n",
    "        tgt_ids.append(EOS_token)\n",
    "        input_ids[idx, :len(inp_ids)] = inp_ids\n",
    "        target_ids[idx, :len(tgt_ids)] = tgt_ids\n",
    "\n",
    "    train_data = TensorDataset(torch.LongTensor(input_ids).to(device),\n",
    "                               torch.LongTensor(target_ids).to(device))\n",
    "\n",
    "    train_sampler = RandomSampler(train_data)\n",
    "    train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
    "    return input_lang, output_lang, train_dataloader"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-19T10:15:57.230183996Z",
     "start_time": "2023-10-19T10:15:57.228861342Z"
    }
   },
   "id": "dcd7a021ddd23930"
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "teacher_forcing_ratio = 0.5\n",
    "\n",
    "\n",
    "def train(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, max_length=MAX_LENGTH):\n",
    "    encoder_hidden = encoder.initHidden()\n",
    "\n",
    "    encoder_optimizer.zero_grad()\n",
    "    decoder_optimizer.zero_grad()\n",
    "\n",
    "    input_length = input_tensor.size(0)\n",
    "    target_length = target_tensor.size(0)\n",
    "\n",
    "    encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
    "\n",
    "    loss = 0\n",
    "\n",
    "    for ei in range(input_length):\n",
    "        encoder_output, encoder_hidden = encoder(\n",
    "            input_tensor[ei], encoder_hidden)\n",
    "        encoder_outputs[ei] = encoder_output[0, 0]\n",
    "\n",
    "    decoder_input = torch.tensor([[SOS_token]], device=device)\n",
    "\n",
    "    decoder_hidden = encoder_hidden\n",
    "\n",
    "    use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\n",
    "\n",
    "    if use_teacher_forcing:\n",
    "        # Teacher forcing: Feed the target as the next input\n",
    "        for di in range(target_length):\n",
    "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
    "                decoder_input, decoder_hidden, encoder_outputs)\n",
    "            loss += criterion(decoder_output, target_tensor[di])\n",
    "            decoder_input = target_tensor[di]  # Teacher forcing\n",
    "\n",
    "    else:\n",
    "        # Without teacher forcing: use its own predictions as the next input\n",
    "        for di in range(target_length):\n",
    "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
    "                decoder_input, decoder_hidden, encoder_outputs)\n",
    "            topv, topi = decoder_output.topk(1)\n",
    "            decoder_input = topi.squeeze().detach()  # detach from history as input\n",
    "\n",
    "            loss += criterion(decoder_output, target_tensor[di])\n",
    "            if decoder_input.item() == EOS_token:\n",
    "                break\n",
    "\n",
    "    loss.backward()\n",
    "\n",
    "    encoder_optimizer.step()\n",
    "    decoder_optimizer.step()\n",
    "\n",
    "    return loss.item() / target_length"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-19T10:15:57.230427140Z",
     "start_time": "2023-10-19T10:15:57.228990137Z"
    }
   },
   "id": "265d65ac5aa7c02e"
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.switch_backend('agg')\n",
    "import matplotlib.ticker as ticker\n",
    "import numpy as np\n",
    "\n",
    "def showPlot(points):\n",
    "    plt.figure()\n",
    "    fig, ax = plt.subplots()\n",
    "    # this locator puts ticks at regular intervals\n",
    "    loc = ticker.MultipleLocator(base=0.2)\n",
    "    ax.yaxis.set_major_locator(loc)\n",
    "    plt.plot(points)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-19T10:15:57.408368076Z",
     "start_time": "2023-10-19T10:15:57.229152077Z"
    }
   },
   "id": "c36d0729e2c33536"
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "def trainIters(encoder, decoder, n_iters, print_every=1000, plot_every=100):\n",
    "    start = time.time()\n",
    "    plot_losses = []\n",
    "    print_loss_total = 0  # Reset every print_every\n",
    "    plot_loss_total = 0  # Reset every plot_every\n",
    "\n",
    "    encoder_optimizer = optim.Adagrad(encoder.parameters())\n",
    "    decoder_optimizer = optim.Adagrad(decoder.parameters())\n",
    "    training_pairs = [tensorsFromPair(random.choice(pairs))\n",
    "                      for i in range(n_iters)]\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    for iter in range(1, n_iters + 1):\n",
    "        training_pair = training_pairs[iter - 1]\n",
    "        input_tensor = training_pair[0]\n",
    "        target_tensor = training_pair[1]\n",
    "\n",
    "        loss = train(input_tensor, target_tensor, encoder,\n",
    "                     decoder, encoder_optimizer, decoder_optimizer, criterion)\n",
    "        print_loss_total += loss\n",
    "        plot_loss_total += loss\n",
    "\n",
    "        if iter % print_every == 0:\n",
    "            print_loss_avg = print_loss_total / print_every\n",
    "            print_loss_total = 0\n",
    "            print('%s (%d %d%%) %.4f' % (timeSince(start, iter / n_iters),\n",
    "                                         iter, iter / n_iters * 100, print_loss_avg))\n",
    "\n",
    "        if iter % plot_every == 0:\n",
    "            plot_loss_avg = plot_loss_total / plot_every\n",
    "            plot_losses.append(plot_loss_avg)\n",
    "            plot_loss_total = 0\n",
    "\n",
    "    showPlot(plot_losses)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-19T10:15:57.413101268Z",
     "start_time": "2023-10-19T10:15:57.410308218Z"
    }
   },
   "id": "977a1d6178ce2a0a"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# The Translation"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4b121a27f039233b"
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "def evaluate(encoder, decoder, sentence, input_lang, output_lang):\n",
    "    with torch.no_grad():\n",
    "        input_tensor = tensorFromSentence(input_lang, sentence)\n",
    "\n",
    "        encoder_outputs, encoder_hidden = encoder(input_tensor)\n",
    "        decoder_outputs, decoder_hidden, decoder_attn = decoder(encoder_outputs, encoder_hidden)\n",
    "\n",
    "        _, topi = decoder_outputs.topk(1)\n",
    "        decoded_ids = topi.squeeze()\n",
    "\n",
    "        decoded_words = []\n",
    "        for idx in decoded_ids:\n",
    "            if idx.item() == EOS_token:\n",
    "                decoded_words.append('<EOS>')\n",
    "                break\n",
    "            decoded_words.append(output_lang.index2word[idx.item()])\n",
    "    return decoded_words, decoder_attn"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-19T10:15:57.456441389Z",
     "start_time": "2023-10-19T10:15:57.412800183Z"
    }
   },
   "id": "501e6af5588cc050"
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "def evaluateRandomly(encoder, decoder, n=10):\n",
    "    for i in range(n):\n",
    "        pair = random.choice(pairs)\n",
    "        print('>', pair[0])\n",
    "        print('=', pair[1])\n",
    "        output_words, _ = evaluate(encoder, decoder, pair[0], input_lang, output_lang)\n",
    "        output_sentence = ' '.join(output_words)\n",
    "        print('<', output_sentence)\n",
    "        print('')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-19T10:15:57.457018801Z",
     "start_time": "2023-10-19T10:15:57.456309848Z"
    }
   },
   "id": "7d1b059d06a1c521"
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "input.size(-1) must be equal to input_size. Expected 1536, got 10752",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[18], line 5\u001B[0m\n\u001B[1;32m      2\u001B[0m encoder \u001B[38;5;241m=\u001B[39m EncoderRNN(input_lang\u001B[38;5;241m.\u001B[39mn_words, hidden_size)\u001B[38;5;241m.\u001B[39mto(device)\n\u001B[1;32m      3\u001B[0m attn_decoder \u001B[38;5;241m=\u001B[39m AttnDecoderRNN(hidden_size, output_lang\u001B[38;5;241m.\u001B[39mn_words, dropout_p\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0.1\u001B[39m)\u001B[38;5;241m.\u001B[39mto(device)\n\u001B[0;32m----> 5\u001B[0m \u001B[43mtrainIters\u001B[49m\u001B[43m(\u001B[49m\u001B[43mencoder\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mattn_decoder\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m75000\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mprint_every\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m5000\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[0;32mIn[15], line 18\u001B[0m, in \u001B[0;36mtrainIters\u001B[0;34m(encoder, decoder, n_iters, print_every, plot_every)\u001B[0m\n\u001B[1;32m     15\u001B[0m input_tensor \u001B[38;5;241m=\u001B[39m training_pair[\u001B[38;5;241m0\u001B[39m]\n\u001B[1;32m     16\u001B[0m target_tensor \u001B[38;5;241m=\u001B[39m training_pair[\u001B[38;5;241m1\u001B[39m]\n\u001B[0;32m---> 18\u001B[0m loss \u001B[38;5;241m=\u001B[39m \u001B[43mtrain\u001B[49m\u001B[43m(\u001B[49m\u001B[43minput_tensor\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtarget_tensor\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mencoder\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     19\u001B[0m \u001B[43m             \u001B[49m\u001B[43mdecoder\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mencoder_optimizer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdecoder_optimizer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcriterion\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     20\u001B[0m print_loss_total \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m loss\n\u001B[1;32m     21\u001B[0m plot_loss_total \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m loss\n",
      "Cell \u001B[0;32mIn[13], line 18\u001B[0m, in \u001B[0;36mtrain\u001B[0;34m(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, max_length)\u001B[0m\n\u001B[1;32m     15\u001B[0m loss \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0\u001B[39m\n\u001B[1;32m     17\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m ei \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(input_length):\n\u001B[0;32m---> 18\u001B[0m     encoder_output, encoder_hidden \u001B[38;5;241m=\u001B[39m \u001B[43mencoder\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m     19\u001B[0m \u001B[43m        \u001B[49m\u001B[43minput_tensor\u001B[49m\u001B[43m[\u001B[49m\u001B[43mei\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mencoder_hidden\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     20\u001B[0m     encoder_outputs[ei] \u001B[38;5;241m=\u001B[39m encoder_output[\u001B[38;5;241m0\u001B[39m, \u001B[38;5;241m0\u001B[39m]\n\u001B[1;32m     22\u001B[0m decoder_input \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mtensor([[SOS_token]], device\u001B[38;5;241m=\u001B[39mdevice)\n",
      "File \u001B[0;32m~/Projects/Neural Machine Translation/venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1516\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1517\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1518\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Projects/Neural Machine Translation/venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1527\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1522\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1523\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1524\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1525\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1526\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1527\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1529\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m   1530\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "Cell \u001B[0;32mIn[9], line 12\u001B[0m, in \u001B[0;36mEncoderRNN.forward\u001B[0;34m(self, input, hidden)\u001B[0m\n\u001B[1;32m     10\u001B[0m embedded \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39membedding(\u001B[38;5;28minput\u001B[39m)\u001B[38;5;241m.\u001B[39mview(\u001B[38;5;241m1\u001B[39m, \u001B[38;5;241m1\u001B[39m, \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m)\n\u001B[1;32m     11\u001B[0m output \u001B[38;5;241m=\u001B[39m embedded\n\u001B[0;32m---> 12\u001B[0m output, hidden \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgru\u001B[49m\u001B[43m(\u001B[49m\u001B[43moutput\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mhidden\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     13\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m output, hidden\n",
      "File \u001B[0;32m~/Projects/Neural Machine Translation/venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1516\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1517\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1518\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Projects/Neural Machine Translation/venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1527\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1522\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1523\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1524\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1525\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1526\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1527\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1529\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m   1530\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[0;32m~/Projects/Neural Machine Translation/venv/lib/python3.11/site-packages/torch/nn/modules/rnn.py:1100\u001B[0m, in \u001B[0;36mGRU.forward\u001B[0;34m(self, input, hx)\u001B[0m\n\u001B[1;32m   1095\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m   1096\u001B[0m         \u001B[38;5;66;03m# Each batch of the hidden state should match the input sequence that\u001B[39;00m\n\u001B[1;32m   1097\u001B[0m         \u001B[38;5;66;03m# the user believes he/she is passing in.\u001B[39;00m\n\u001B[1;32m   1098\u001B[0m         hx \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpermute_hidden(hx, sorted_indices)\n\u001B[0;32m-> 1100\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcheck_forward_args\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mhx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbatch_sizes\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1101\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m batch_sizes \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m   1102\u001B[0m     result \u001B[38;5;241m=\u001B[39m _VF\u001B[38;5;241m.\u001B[39mgru(\u001B[38;5;28minput\u001B[39m, hx, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_flat_weights, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbias, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mnum_layers,\n\u001B[1;32m   1103\u001B[0m                      \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdropout, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtraining, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbidirectional, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbatch_first)\n",
      "File \u001B[0;32m~/Projects/Neural Machine Translation/venv/lib/python3.11/site-packages/torch/nn/modules/rnn.py:270\u001B[0m, in \u001B[0;36mRNNBase.check_forward_args\u001B[0;34m(self, input, hidden, batch_sizes)\u001B[0m\n\u001B[1;32m    269\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mcheck_forward_args\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;28minput\u001B[39m: Tensor, hidden: Tensor, batch_sizes: Optional[Tensor]):\n\u001B[0;32m--> 270\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcheck_input\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbatch_sizes\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    271\u001B[0m     expected_hidden_size \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mget_expected_hidden_size(\u001B[38;5;28minput\u001B[39m, batch_sizes)\n\u001B[1;32m    273\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcheck_hidden_size(hidden, expected_hidden_size)\n",
      "File \u001B[0;32m~/Projects/Neural Machine Translation/venv/lib/python3.11/site-packages/torch/nn/modules/rnn.py:236\u001B[0m, in \u001B[0;36mRNNBase.check_input\u001B[0;34m(self, input, batch_sizes)\u001B[0m\n\u001B[1;32m    233\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mRuntimeError\u001B[39;00m(\n\u001B[1;32m    234\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124minput must have \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mexpected_input_dim\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m dimensions, got \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28minput\u001B[39m\u001B[38;5;241m.\u001B[39mdim()\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m    235\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39minput_size \u001B[38;5;241m!=\u001B[39m \u001B[38;5;28minput\u001B[39m\u001B[38;5;241m.\u001B[39msize(\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m):\n\u001B[0;32m--> 236\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mRuntimeError\u001B[39;00m(\n\u001B[1;32m    237\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124minput.size(-1) must be equal to input_size. Expected \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39minput_size\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m, got \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28minput\u001B[39m\u001B[38;5;241m.\u001B[39msize(\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m)\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m)\n",
      "\u001B[0;31mRuntimeError\u001B[0m: input.size(-1) must be equal to input_size. Expected 1536, got 10752"
     ]
    }
   ],
   "source": [
    "hidden_size = 1536\n",
    "encoder = EncoderRNN(input_lang.n_words, hidden_size).to(device)\n",
    "attn_decoder = AttnDecoderRNN(hidden_size, output_lang.n_words, dropout_p=0.1).to(device)\n",
    "\n",
    "trainIters(encoder, attn_decoder, 75000, print_every=5000)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-19T10:16:01.618567297Z",
     "start_time": "2023-10-19T10:15:57.456855149Z"
    }
   },
   "id": "10d866385e54900e"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "encoder.eval()\n",
    "attn_decoder.eval()\n",
    "evaluateRandomly(encoder, attn_decoder)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "161ebedb43c9b1a0"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
